{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell0",
   "metadata": {},
   "source": [
    "Learning to rank.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d580da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wvpy.jtools import declare_task_variables\n",
    "\n",
    "# set up for external override\n",
    "with declare_task_variables(globals()):\n",
    "    rand_seed = 2024\n",
    "    do_display = True\n",
    "    result_fname = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Python\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from cmdstanpy import CmdStanModel\n",
    "from plotnine import *\n",
    "from rank_plotting_fns import plot_rank_performance, run_stan_model\n",
    "\n",
    "# quiet down Stan\n",
    "logger = logging.getLogger(\"cmdstanpy\")\n",
    "logger.addHandler(logging.NullHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(rand_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_name = \"uci wine example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_display:\n",
    "    print(example_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if example_name == \"uci wine example\":\n",
    "    # read data and set scale of system\n",
    "    features_frame = pd.read_csv(\"uci_wine_example_features.csv\")\n",
    "    features_scores = pd.read_csv(\"uci_wine_example_scores.csv\")\n",
    "    score_name = \"logistic_score\"\n",
    "    m_examples: int = 100\n",
    "    noise_scale = 3.87\n",
    "    position_penalty_scale = -2.7123\n",
    "elif example_name == \"sklearn wine example\":\n",
    "    # read data and set scale of system\n",
    "    features_frame = pd.read_csv(\"sklearn_wine_example_features.csv\")\n",
    "    features_scores = pd.read_csv(\"sklearn_wine_example_scores.csv\")\n",
    "    score_name = \"score\"\n",
    "    m_examples: int = 100\n",
    "    noise_scale = 18.7\n",
    "    position_penalty_scale = -13.123\n",
    "else:\n",
    "    raise (\"bad option\")\n",
    "\n",
    "know_score: bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35eb1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alternatives: int = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e917c543",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vars = features_frame.shape[1] + n_alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell9",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_penalties = [position_penalty_scale * i for i in range(n_alternatives)]\n",
    "\n",
    "position_penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assemble panels of observations with top scoring entry picked\n",
    "observations = dict()\n",
    "for sel_i in range(n_alternatives):\n",
    "    observations[f\"display_position_{sel_i}\"] = [sel_i] * m_examples\n",
    "    selected_examples = rng.choice(\n",
    "        features_frame.shape[0], size=m_examples, replace=True\n",
    "    )\n",
    "    observations[f\"item_id_{sel_i}\"] = selected_examples\n",
    "    observations[f\"score_value_{sel_i}\"] = (\n",
    "        [  # noisy observation of score plus position penalty\n",
    "            features_scores.loc[int(selected_examples[i]), score_name]  # item score\n",
    "            + position_penalties[sel_i]  # positional penalty\n",
    "            + noise_scale * rng.normal(size=1)[0]  # observation noise\n",
    "            for i in range(m_examples)\n",
    "        ]\n",
    "    )\n",
    "    observations[f\"pick_value_{sel_i}\"] = [0] * m_examples\n",
    "observations = pd.DataFrame(observations)\n",
    "# mark selections\n",
    "for i in range(m_examples):\n",
    "    best_j = 0\n",
    "    for j in range(1, n_alternatives):\n",
    "        if (\n",
    "            observations[f\"score_value_{j}\"][i]\n",
    "            > observations[f\"score_value_{best_j}\"][i]\n",
    "        ):\n",
    "            best_j = j\n",
    "    observations.loc[i, f\"pick_value_{best_j}\"] = 1\n",
    "# make sure we don't have a column we would not know in practice\n",
    "observations = observations.loc[\n",
    "    :, [c for c in observations.columns if not c.startswith(\"score_value_\")]\n",
    "].reset_index(drop=True, inplace=False)\n",
    "\n",
    "observations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell11",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations.loc[\n",
    "    :, [c for c in observations.columns if c.startswith(\"pick_value_\")]\n",
    "].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the data\n",
    "observations[\n",
    "    [c for c in observations.columns if not c.startswith(\"display_position_\")]\n",
    "].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell14",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_compare_frame = pd.DataFrame([[] for i in range(features_frame.shape[0])])\n",
    "if know_score:\n",
    "    score_compare_frame[\"hidden concept\"] = features_scores[score_name]  # would not know this for non-synthetic data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell15",
   "metadata": {},
   "source": [
    "Try a Stan model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# swap all observed alternatives selections into picked position\n",
    "observations_sorted = observations.copy()\n",
    "for passed_i in range(1, n_alternatives):\n",
    "    for row_i in range(m_examples):\n",
    "        if observations_sorted.loc[row_i, f\"pick_value_{passed_i}\"] > 0:\n",
    "            # swap where data is stored in row\n",
    "            for dest_col, source_col in (\n",
    "                (\"display_position_0\", f\"display_position_{passed_i}\"),\n",
    "                (\"item_id_0\", f\"item_id_{passed_i}\"),\n",
    "                (\"pick_value_0\", f\"pick_value_{passed_i}\"),\n",
    "            ):\n",
    "                v_source = observations_sorted.loc[row_i, source_col]\n",
    "                v_dest = observations_sorted.loc[row_i, dest_col]\n",
    "                observations_sorted.loc[row_i, source_col] = v_dest\n",
    "                observations_sorted.loc[row_i, dest_col] = v_source\n",
    "observations_sorted.rename(columns={f'display_position_{i}': f'encoding_{i}' for i in range(n_alternatives)}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell17",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell19",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations_sorted[\n",
    "    [\n",
    "        c\n",
    "        for c in observations_sorted.columns\n",
    "        if not c.startswith(\"pick_value_\")\n",
    "    ]\n",
    "].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell20",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(observations_sorted[\"pick_value_0\"] == 1)\n",
    "for sel_i in range(1, n_alternatives):\n",
    "    assert np.all(observations_sorted[f\"pick_value_{sel_i}\"] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell21",
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_model_panel_src = (\n",
    "    \"\"\"\n",
    "data {\n",
    "  int<lower=1> n_vars;                     // number of variables per alternative\n",
    "  int<lower=1> m_examples;                 // number of examples\n",
    "  matrix[m_examples, n_vars] x_picked;     // character of picked examples\n",
    "\"\"\"\n",
    "    + \"\".join(\n",
    "        [\n",
    "            f\"\"\"  matrix[m_examples, n_vars] x_passed_{i};   // character of passed examples\n",
    "\"\"\"\n",
    "            for i in range(1, n_alternatives)\n",
    "        ]\n",
    "    )\n",
    "    + \"\"\"}\n",
    "parameters {\n",
    "  vector[n_vars] beta;                      // model parameters\n",
    "  vector[m_examples] error_picked;          // reified noise term on picks (the secret sauce!)\n",
    "}\n",
    "transformed parameters {\n",
    "  vector[m_examples] expect_picked;\n",
    "  vector[m_examples] v_picked;\n",
    "\"\"\"\n",
    "    + \"\".join(\n",
    "        [\n",
    "            f\"\"\"  vector[m_examples] expect_passed_{i};\n",
    "\"\"\"\n",
    "            for i in range(1, n_alternatives)\n",
    "        ]\n",
    "    )\n",
    "    + \"\"\"  expect_picked = x_picked * beta;          // modeled expected score of picked item\n",
    "  v_picked = expect_picked + error_picked;  // reified actual score of picked item\n",
    "\"\"\"\n",
    "    + \"\".join(\n",
    "        [\n",
    "            f\"\"\"  expect_passed_{i} = x_passed_{i} * beta;      // modeled expected score of passed item\n",
    "\"\"\"\n",
    "            for i in range(1, n_alternatives)\n",
    "        ]\n",
    "    )\n",
    "    + \"\"\"}\n",
    "model {\n",
    "    // basic priors\n",
    "  beta ~ normal(0, 10);\n",
    "  error_picked ~ normal(0, 10);\n",
    "    // log probability of observed ordering as a function of parameters\n",
    "    // terms are independent conditioned on knowing value of v_picked!\n",
    "\"\"\"\n",
    "    + \"\".join(\n",
    "        [\n",
    "            f\"\"\"  target += normal_lcdf( v_picked | expect_passed_{i}, 10);\n",
    "\"\"\"\n",
    "            for i in range(1, n_alternatives)\n",
    "        ]\n",
    "    )\n",
    "    + \"\"\"}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "if do_display:\n",
    "    print(stan_model_panel_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmt_array(a) -> str:\n",
    "    return json.dumps([v for v in a])\n",
    "\n",
    "\n",
    "def mk_posn_indicator(posn: int) -> str:\n",
    "    posn_indicators = [0] * n_alternatives\n",
    "    posn_indicators[posn] = 1\n",
    "    return posn_indicators\n",
    "\n",
    "\n",
    "def f_i(sel_i: int) -> str:\n",
    "    id_seq = observations_sorted[f\"item_id_{sel_i}\"]\n",
    "    posn_seq = observations_sorted[f\"encoding_{sel_i}\"]\n",
    "    return fmt_array(\n",
    "        [\n",
    "            list(features_frame.loc[int(id), :]) + mk_posn_indicator(int(posn))\n",
    "            for id, posn in zip(id_seq, posn_seq)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "data_str = (\n",
    "    f\"\"\"\n",
    "{{\n",
    " \"n_vars\" : {n_vars},\n",
    " \"m_examples\" : {m_examples},\n",
    " \"x_picked\" : {f_i(0)},\n",
    "\"\"\"\n",
    "    + \"\"\",\n",
    "\"\"\".join(\n",
    "        [f\"\"\" \"x_passed_{i}\" : {f_i(i)}\"\"\" for i in range(1, n_alternatives)]\n",
    "    )\n",
    "    + \"\"\"\n",
    "}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = run_stan_model(\n",
    "    stan_model_src=stan_model_panel_src,\n",
    "    data_str=data_str,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get implied sample weights from chain\n",
    "wt_frame = fit.draws_pd(vars=[\"lp__\"])\n",
    "\n",
    "wt_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell25",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_display:\n",
    "    stddev = np.sqrt(np.var(wt_frame['lp__']))\n",
    "    log_samples = np.log(wt_frame.shape[0])\n",
    "    (\n",
    "        ggplot(\n",
    "            data=wt_frame,\n",
    "            mapping=aes(x=\"lp__\"),\n",
    "        )\n",
    "        + geom_density(fill=\"gray\", alpha=0.7)\n",
    "        + ggtitle(f\"{example_name} Stan lp__ value on panel draws\\nstandard deviation: {stddev:.2f}, log samples = {log_samples:.2f}\")\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9848406e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell26",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_draws = fit.draws_pd(vars=[\"beta\"])\n",
    "beta_draws_display = beta_draws.copy()\n",
    "beta_draws_display.columns = list(features_frame.columns) + [\n",
    "    f\"position_effect_{sel_i}\" for sel_i in range(n_alternatives)\n",
    "]\n",
    "\n",
    "beta_draws_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this this entirety of what we pull out of Stan- per modeled preference cohort\n",
    "# from now on we do not use Stan\n",
    "estimated_beta_Stan = beta_draws_display.loc[\n",
    "    wt_frame[\"lp__\"] >= np.quantile(wt_frame[\"lp__\"], 0.9), :\n",
    "].mean()\n",
    "# estimated_beta_Stan = beta_draws_display.mean()\n",
    "estimated_beta_Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell28",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_quantiles = (\n",
    "    beta_draws.iloc[:, features_frame.shape[1] : n_vars]\n",
    "    .quantile((0.25, 0.5, 0.75))\n",
    "    .transpose()\n",
    "    .reset_index(drop=True, inplace=False)\n",
    ")\n",
    "position_quantiles.columns = [str(c) for c in position_quantiles.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell29",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_pull = plot_rank_performance(\n",
    "    estimated_beta=estimated_beta_Stan,  # estimated coefficients\n",
    "    example_name=example_name,  # name of data set\n",
    "    n_vars=n_vars,  # number of variables (including position variables)\n",
    "    n_alternatives=n_alternatives,  # size of panels\n",
    "    features_frame=features_frame,  # features by row id\n",
    "    observations=observations,  # observations layout frame\n",
    "    estimate_name=\"Stan panel model\",  # display name of estimate\n",
    "    position_quantiles=position_quantiles,  # quantiles of estimated positions\n",
    "    position_penalties=position_penalties,  # ideal position penalties\n",
    "    score_compare_frame=score_compare_frame,  # score comparison frame (altered by call)\n",
    "    rng=rng,  # pseudo random source\n",
    "    show_plots=do_display,\n",
    ")\n",
    "collected_stats.append(stat_pull)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell30",
   "metadata": {},
   "source": [
    "Try to approximate the Stan model with a logistic model with similar error structure.\n",
    "Consider each pair of panel entries with a different outcome as an observation and try to\n",
    "build a model that reproduces the observed outcomes.\n",
    "The extra trick is: repeat the whole data frame negated with the outcomes reverse (so \n",
    "we don't define a problem with all positive or all negative outcomes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell31",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(features_frame.columns) + [\n",
    "    f\"position_{sel_i}\" for sel_i in range(n_alternatives)\n",
    "]\n",
    "enc_frame = []\n",
    "for row_i in range(observations.shape[0]):\n",
    "    feature_row = observations.loc[row_i, :]\n",
    "    sel_pick = np.argmax(\n",
    "        feature_row[[f\"pick_value_{sel_i}\" for sel_i in range(n_alternatives)]]\n",
    "    )\n",
    "    for sel_i in range(n_alternatives):\n",
    "        if sel_i != sel_pick:\n",
    "            posn_vec = [0] * n_alternatives\n",
    "            posn_vec[sel_pick] = 1.0\n",
    "            posn_vec[sel_i] = -1.0\n",
    "            encoded_row = (\n",
    "                list(\n",
    "                    features_frame.loc[feature_row[f\"item_id_{sel_pick}\"], :]\n",
    "                    - features_frame.loc[feature_row[f\"item_id_{sel_i}\"], :]\n",
    "                )\n",
    "                + posn_vec\n",
    "            )\n",
    "            di = pd.DataFrame({k: [v] for k, v in zip(feature_names, encoded_row)})\n",
    "            enc_frame.append(di)\n",
    "enc_frame = pd.concat(enc_frame, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell32",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell33",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(max_iter=10000, solver=\"newton-cholesky\")\n",
    "logistic_model.fit(\n",
    "    pd.concat([enc_frame, -enc_frame], ignore_index=True),\n",
    "    [True] * enc_frame.shape[0] + [False] * enc_frame.shape[0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell34",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_pull = plot_rank_performance(\n",
    "    estimated_beta=logistic_model.coef_[0],  # estimated coefficients\n",
    "    example_name=example_name,  # name of data set\n",
    "    n_vars=n_vars,  # number of variables (including position variables)\n",
    "    n_alternatives=n_alternatives,  # size of panels\n",
    "    features_frame=features_frame,  # features by row id\n",
    "    observations=observations,  # observations layout frame\n",
    "    estimate_name=\"logistic model\",  # display name of estimate\n",
    "    position_quantiles=None,  # quantiles of estimated positions\n",
    "    position_penalties=position_penalties,  # ideal position penalties\n",
    "    score_compare_frame=score_compare_frame,  # score comparison frame (altered by call)\n",
    "    rng=rng,  # pseudo random source\n",
    "    show_plots=do_display,\n",
    ")\n",
    "collected_stats.append(stat_pull)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecacdbf",
   "metadata": {},
   "source": [
    "We can also try a related Stan model per-comparison, instead of per-panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedaa7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stan_model_comparison_src = (\n",
    "    \"\"\"\n",
    "data {\n",
    "  int<lower=1> n_vars;                     // number of variables per alternative\n",
    "  int<lower=1> m_examples;                 // number of examples\n",
    "  matrix[m_examples, n_vars] x_picked;     // character of picked examples\n",
    "\"\"\"\n",
    "    + \"\".join(\n",
    "        [\n",
    "            f\"\"\"  matrix[m_examples, n_vars] x_passed_{i};   // character of passed examples\n",
    "\"\"\"\n",
    "            for i in range(1, n_alternatives)\n",
    "        ]\n",
    "    )\n",
    "    + \"\"\"}\n",
    "parameters {\n",
    "  vector[n_vars] beta;                      // model parameters\n",
    "}\n",
    "transformed parameters {\n",
    "  vector[m_examples] expect_picked;\n",
    "\"\"\"\n",
    "    + \"\".join(\n",
    "        [\n",
    "            f\"\"\"  vector[m_examples] expect_passed_{i};\n",
    "\"\"\"\n",
    "            for i in range(1, n_alternatives)\n",
    "        ]\n",
    "    )\n",
    "    + \"\"\"  expect_picked = x_picked * beta;          // modeled expected score of picked item\n",
    "\"\"\"\n",
    "    + \"\".join(\n",
    "        [\n",
    "            f\"\"\"  expect_passed_{i} = x_passed_{i} * beta;      // modeled expected score of passed item\n",
    "\"\"\"\n",
    "            for i in range(1, n_alternatives)\n",
    "        ]\n",
    "    )\n",
    "    + \"\"\"}\n",
    "model {\n",
    "    // basic priors\n",
    "  beta ~ normal(0, 10);\n",
    "    // log probability of observed ordering as a function of parameters\n",
    "\"\"\"\n",
    "    + \"\".join(\n",
    "        [\n",
    "            f\"\"\"  target += normal_lcdf( 0 | expect_passed_{i} - expect_picked, sqrt(2) * 10);\n",
    "\"\"\"\n",
    "            for i in range(1, n_alternatives)\n",
    "        ]\n",
    "    )\n",
    "    + \"\"\"}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "if do_display:\n",
    "    print(stan_model_comparison_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdad476",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_comp = run_stan_model(\n",
    "    stan_model_src=stan_model_comparison_src,\n",
    "    data_str=data_str,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f514bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get implied sample weights from chain\n",
    "wt_frame_c = fit_comp.draws_pd(vars=[\"lp__\"])\n",
    "if do_display:\n",
    "    stddev_c = np.sqrt(np.var(wt_frame_c['lp__']))\n",
    "    log_samples_c = np.log(wt_frame_c.shape[0])\n",
    "    (\n",
    "        ggplot(\n",
    "            data=wt_frame_c,\n",
    "            mapping=aes(x=\"lp__\"),\n",
    "        )\n",
    "        + geom_density(fill=\"gray\", alpha=0.7)\n",
    "        + ggtitle(f\"{example_name} Stan lp__ value on comparison draws\\nstandard deviation: {stddev_c:.2f}, log samples = {log_samples_c:.2f}\")\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0681a3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_draws_c = fit_comp.draws_pd(vars=[\"beta\"])\n",
    "estimated_beta_Stan_c = beta_draws_c.loc[\n",
    "    wt_frame_c[\"lp__\"] >= np.quantile(wt_frame_c[\"lp__\"], 0.9), :\n",
    "].mean()\n",
    "# estimated_beta_Stan_c = beta_draws_c.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5990e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_quantiles_c = (\n",
    "    beta_draws_c.iloc[:, features_frame.shape[1] : n_vars]\n",
    "    .quantile((0.25, 0.5, 0.75))\n",
    "    .transpose()\n",
    "    .reset_index(drop=True, inplace=False)\n",
    ")\n",
    "position_quantiles_c.columns = [str(c) for c in position_quantiles_c.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5965c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_pull = plot_rank_performance(\n",
    "    estimated_beta=estimated_beta_Stan_c,  # estimated coefficients\n",
    "    example_name=example_name,  # name of data set\n",
    "    n_vars=n_vars,  # number of variables (including position variables)\n",
    "    n_alternatives=n_alternatives,  # size of panels\n",
    "    features_frame=features_frame,  # features by row id\n",
    "    observations=observations,  # observations layout frame\n",
    "    estimate_name=\"Stan comparisons model\",  # display name of estimate\n",
    "    position_quantiles=position_quantiles_c,  # quantiles of estimated positions\n",
    "    position_penalties=position_penalties,  # ideal position penalties\n",
    "    score_compare_frame=score_compare_frame,  # score comparison frame (altered by call)\n",
    "    rng=rng,  # pseudo random source\n",
    "    show_plots=do_display,\n",
    ")\n",
    "collected_stats.append(stat_pull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1f4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "collected_stats = pd.concat(collected_stats, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ff9bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (result_fname is not None) and (len(result_fname) > 0):\n",
    "    collected_stats.to_csv(result_fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bd1049",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_display:\n",
    "    display(collected_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prob_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
