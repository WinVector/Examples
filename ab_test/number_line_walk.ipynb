{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell0",
   "metadata": {},
   "source": [
    "# The Drunkard's Walk In Detail\n",
    "\n",
    "## Introduction\n",
    "\n",
    "I would like to spend some time on a simple random walk on the non-negative integers <code>0 ... k</code> called \"the drunkard's walk\"  A *lot* of intuition can be had by studying the this system. This note is a quicker way to derive some of the observations found in [\"A Slightly Unfair Game\"](https://win-vector.com/2023/10/30/a-slightly-unfair-game/).\n",
    "\n",
    "I have found this differs from many treatments of Markov chains in that we are analyzing an \"absorbing chain\" (instead of a \"regular\" or \"ergodic\" one, see Kemeny, Snell, *Finite Markov Chains*, 2nd Edition, 1976, Springer Verlag) and we are using bespoke recurrence arguments instead of the usual move to linear algebra.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell1",
   "metadata": {},
   "source": [
    "## The drunkard's walk\n",
    "\n",
    "Pick an integer <code>k &gt; 0</code>. Then the states of our random process are the integers <code>0</code> through <code>k</code>. The integers <code>0</code> and <code>k</code> are both \"stop conditions\" called \"stop zero\" and \"stop non-zero\". For an integer <code>i</code> strictly larger than <code>0</code> and strictly less than <code>k</code>, our random process is: pick the next integer to be either <code>i-1</code> or <code>i+1</code> with equal probability. We stop the process when <code>i</code> is either <code>0</code> or <code>k</code>. This is called a \"random walk\" and is often known as \"the drunkard's walk\". Some variations have \"stay probabilities\", but we will not need these here.\n",
    "\n",
    "What isn't emphasized enough is: a lot can be quickly seen for this walk, without using complicated tools or arguments. In particular we can quickly show the following.\n",
    "\n",
    "  1) The probability of a walk started in state-</code>i</code> \"stopping non-zero\" (first reaching <code>k</code>, with no prior visits to <code>0</code>) is <code>i/k</code>.\n",
    "  2) The expected time of a walk started in state-</code>i</code> to hit either of the stopping conditions (reaching <code>0</code> or <code>k</code> for the first time) is <code>i * (k - i)</code>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell2",
   "metadata": {},
   "source": [
    "## Deriving the probability of \"stopping non-zero\"\n",
    "\n",
    "Let <code>prob_pos<sub>k</sub>(i)</code> denote the probability that the drunkard's walk started at integer <code>i</code> (</code>0 &le; i &le; k</code>) stops at <code>k</code> before ever visiting <code>0</code>.\n",
    "\n",
    "For any <code>i</code> with <code>0&lt;i&lt;k</code> we can expand <code>prob_pos<sub>k</sub>(i)</code> by one walk step to get: <code>prob_pos<sub>k</sub>(i) = (1/2) prob_pos<sub>k</sub>(i-1) + (1/2) prob_pos<sub>k</sub>(i+1)</code>. It is just a matter of algebra to check that <code>prob_pos<sub>k</sub>(i) = i/k</code> obeys this recurrence, and has the desired values for the boundary <code>i = 0, k</code>.\n",
    "\n",
    "As a warm up we confirm the claim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import sympy\n",
    "\n",
    "i, k = sympy.symbols(\"i k\")\n",
    "\n",
    "check = sympy.expand(\n",
    "    ((1/2) * (i-1)/k + (1/2) * (i+1)/k) \n",
    "    - i/k)\n",
    "assert check == 0\n",
    "\n",
    "print(check)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell4",
   "metadata": {},
   "source": [
    "## Deriving the \"expected time to stop\"\n",
    "\n",
    "Let <code>e_time<sub>k</sub>(i)</code> denote the expected number of steps the drunkard's walk started at integer <code>i</code> (</code>0 &le; i &le; k</code>) takes to reach *either* of <code>0</code> or <code>k</code> for the first time. We are not yet specifying which one is first reached.\n",
    "\n",
    "For any <code>i</code> with <code>0 &lt; i &lt; k</code> we can expand <code>e_time<sub>k</sub>(i)</code> by one walk step to get: <code>e_time<sub>k</sub>(i) = 1 + (1/2) e_time<sub>k</sub>(i-1) + (1/2) e_time<sub>k</sub>(i+1)</code>. It is again, a matter of  algebra to check that <code>e_time<sub>k</sub>(i) = i * (k-i)</code> obeys this recurrence, and has the desired values on the boundary.\n",
    "\n",
    "Let's confirm this claim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "check = sympy.expand(\n",
    "    (1 + (1/2) * (i-1) * (k-(i-1)) + (1/2) * (i+1) * (k-(i+1)))\n",
    "    - i * (k-i))\n",
    "assert check == 0\n",
    "\n",
    "print(check)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell6",
   "metadata": {},
   "source": [
    "The above directly gives us the \"expected time to step distance <code>d</code> is around <code>d**2</code> steps\" observation without the usual appeal to linear of expectation applied to independent variances. Note: we the expected stopping time to hit <code>0</code> is going to often be very different than the time to hit <code>k</code> (and both roughly proportional to the square of how far the specified target is from the start position).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Markov chains\n",
    "\n",
    "For our a given run of our random process call the sequence of states <code>s<sub>0</sub></code>, <code>s<sub>1</sub></code>, ... . Where:\n",
    "\n",
    "  * All the <code>s<sub>j</sub></code> are integers in the range <code>0</code> through <code>k</code>.\n",
    "  * If <code>s<sub>j</sub></code> isn't <code>0</code> or <code>k</code>, then <code>|s<sub>i</sub> - s<sub>j+1</sub>| = 1</code> (the process has not stopped)\n",
    "  * If <code>s<sub>j</sub></code> is <code>0</code> or <code>k</code>, then <code>s<sub>j+1</sub> = s<sub>j</sub></code> (the chain has \"stopped\").\n",
    "\n",
    "Let <code>S<sub>k</sub>(i)</code> denote the set of all possible sequences <code>s</code> of integers obeying the above rules where:\n",
    "\n",
    "  * The first state <code>s<sub>1</sub> = i</code>.\n",
    "  * The \"probability\" of <code>s</code> in <code>S<sub>k</sub>(i)</code> is equal to:\n",
    "     * <code>P[s] = 1</code>, if <code>s<sub>j+1</sub> = s<sub>j</sub></code> for all <code>j</code>. Call such <code>s</code> \"stopped.\"\n",
    "     * <code>P[s] = 0</code>, if <code>s<sub>j+1</sub> != s<sub>j</sub></code> for all <code>j</code>. Call such <code>s</code> \"not stopped.\"\n",
    "     * <code>P[s] = 1/2<sup>j</code></code> where <code>j</code> is the highest index such that <code>s<sub>j+1</sub> != s<sub>j</sub></code>. Call such <code>s</code> \"stopped.\"\n",
    "\n",
    "On can check that the <code>P[s] &ge; 0</code> for all <code>s</code> in <code>S<sub>k</sub>(i)</code>, <code>sum<sub>s in S<sub>k</sub>(i)</sub> = 1</code>, and the non-stopped sequences have probability measure zero (so can be ignored in probability arguments).\n",
    "\n",
    "\n",
    "<code>P[]</code> is computing probability over the spaces of all possible sequences <code>s<sub>i</sub></code> generated by picking increasing or decreasing our state (for non stopped sequences) with 50/50 probability. It is a subtle point: probabilities are a distributional property of the family of all Markov chains, not of any *one* observed realization.\n",
    "\n",
    "The above random process <code>S<sub>k</sub>(i)</code> has \"the Markov property\": history becomes irrelevant. That is:\n",
    "\n",
    "<code>\n",
    "<pre>\n",
    "   P[s<sub>i+1</sub> = v | s<sub>1</sub>=v<sub>1</sub>, ..., s<sub>i</sub>=v<sub>i</sub>] = P[s<sub>i</sub> = v | s<sub>i</sub>=v<sub>i</sub>]\n",
    "</pre>\n",
    "</code>.\n",
    "\n",
    "We often use the Markov property in analysis as follows: we can always pretend we are at the first move in a sequence! <code>P[s<sub>i+1</sub> = v<sub>2</sub> | s<sub>i</sub> = v<sub>1</sub>] = P[s<sub>2</sub> = v<sub>2</sub> | s<sub>1</sub> = v<sub>1</sub>]</code> always. \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
