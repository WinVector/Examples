{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell0",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Stan solution to [nested_model_example.ipynb](nested_model_example.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up Python\n",
    "import re\n",
    "import json\n",
    "import inspect\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Markdown\n",
    "import plotnine\n",
    "from plotnine import *\n",
    "\n",
    "from nested_model_fns import (\n",
    "    define_Stan_model_with_forecast_period,\n",
    "    solve_forecast_by_Stan,\n",
    "    plot_forecast,\n",
    "    extract_sframe_result,\n",
    "    plot_model_quality,\n",
    "    plot_model_quality_by_prefix,\n",
    ")\n",
    "\n",
    "# quiet down Stan\n",
    "logger = logging.getLogger(\"cmdstanpy\")\n",
    "logger.addHandler(logging.NullHandler())\n",
    "\n",
    "# set plot size\n",
    "plotnine.options.figure_size = (16, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e789baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"generating_params.json\", \"r\") as file:\n",
    "    generating_params = json.load(file)\n",
    "modeling_lags = generating_params[\"generating_lags\"]\n",
    "b_z = generating_params[\"b_z\"]\n",
    "b_x = generating_params[\"b_x\"]\n",
    "\n",
    "generating_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "172404a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = pd.read_csv(\"d_train.csv\")\n",
    "d_test = pd.read_csv(\"d_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell2",
   "metadata": {},
   "source": [
    "## Solving again with the Bayesian \"big hammer\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell3",
   "metadata": {},
   "source": [
    "We now try a Bayesian model with the correct generative structure, using the [Stan](https://mc-stan.org/users/interfaces/cmdstan) software package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a Stan model for both transient external regressors and future predictions\n",
    "stan_model_with_forecast_i, stan_model_with_forecast_src_i = (\n",
    "    define_Stan_model_with_forecast_period(\n",
    "        application_lags=modeling_lags,\n",
    "        n_transient_external_regressors=len(b_x),\n",
    "        n_durable_external_regressors=len(b_z),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the model specification\n",
    "print(stan_model_with_forecast_src_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell6",
   "metadata": {},
   "source": [
    "`y` and `y_auto` are supposed to be non-negative (a constraint we have chosen to *not* enforce, as it degraded results, probably by damaging sampling paths).\n",
    "\n",
    "Please keep in mind a distributional statement such as <code>y ~ normal(f(y_auto, x), &sigma;)</code> is actually modeling the residual <code>(y - f(y_auto, x))</code> as being distributed <code>normal(0, &sigma;)</code>. So the above model-block statements are distributional assumptions about *residuals*, as the intended mean is an input to these statements. Thus we are specifying a normal distribution for residuals, not a normal distribution for expected values or predictions. I feel the normal approximation for `y`'s residual is not that bad. A similar statement can be made for `y_auto`'s residuals.\n",
    "\n",
    "All in all: specifying systems to Stan is a compromise in respecting problem structure, and preserving the ability to effectively sample. The specification tends to requires some compromise and experimentation. In my opinion, it isn't quite the case that \"Bayes' Law names only one legitimate inferential network and we can then use that one!\" One is going to have to specify an approximate system. It becomes the user's responsibility to design for a (hopefully) high utility tradeoff between fidelity and realizability.\n",
    "\n",
    "We obviously will not know all the priors. So we hope the problem is somewhat insensitive to them and just set them to not so bad distributions. It is possible to over-worry on priors, and somewhat freeing to just think of them as [regularizations](https://en.wikipedia.org/wiki/Regularization_(mathematics)) or biases for the values in question to be small. Also it sometimes makes sense to fight symmetries or degeneracies in the specification by adding \"complementarity\" constraints such as `b_auto_0 * b_imp_0 ~ normal(0, 0.1)`. This is not a distributional claim we believe, but a trick in saying we expect the product to be small to enforce we expect only one of the two values to be non-negligible. Again, think of the model distributional claims as \"criticisms\" and not if they are prior (before seeing data) or posterior (after seeing data) opinions. Also, don't be profligate with these exotic checks: they break convexity of the function we are optimizing and can make sampling harder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell7",
   "metadata": {},
   "source": [
    "What Stan generates is: thousands of possible trajectories of parameters, and past and future hidden state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from Stan model solutions\n",
    "forecast_soln_i = solve_forecast_by_Stan(\n",
    "    model=stan_model_with_forecast_i,\n",
    "    d_train=d_train,\n",
    "    d_apply=d_test,\n",
    "    durable_external_regressors=[\"z_0\"],\n",
    "    transient_external_regressors=[\"x_0\"],\n",
    ")\n",
    "\n",
    "forecast_soln_i  # see https://mc-stan.org/docs/cmdstan-guide/stansummary.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8692766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp__q_90 = forecast_soln_i['lp__'].quantile(q=0.9)\n",
    "(\n",
    "    ggplot(\n",
    "        data=forecast_soln_i,\n",
    "        mapping=aes(x='lp__')\n",
    "    )\n",
    "    + geom_density(fill=\"darkgrey\", alpha=0.5)\n",
    "    + geom_vline(xintercept=lp__q_90, linetype=\"dashed\")\n",
    "    + ggtitle(\"distribution of pseudo log-likelihood\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f07c9ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a trick I like: limit down to the more plausible samples/trajectories\n",
    "forecast_soln_i = (\n",
    "    forecast_soln_i.loc[\n",
    "        forecast_soln_i['lp__'] >= lp__q_90,\n",
    "        :\n",
    "    ].reset_index(drop=True, inplace=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell9",
   "metadata": {},
   "source": [
    "We can look at a summary of the parameter estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize parameter estimates\n",
    "soln_params_i = forecast_soln_i.loc[\n",
    "    :, [c for c in forecast_soln_i if c.startswith(\"b_\")]\n",
    "].median()\n",
    "\n",
    "soln_params_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show original generative parameters\n",
    "generating_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c257767b",
   "metadata": {},
   "source": [
    "Notice we recover `b_x_dur ~ b_z` and `b_x_imp ~ b_x` pretty well. These effect inferences can be used for planning and policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell12",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_frame = pd.DataFrame(\n",
    "    {\n",
    "        \"b_x_dur[0]\": [generating_params[\"b_z\"][0]],\n",
    "        \"b_x_imp[0]\": [generating_params[\"b_x\"][0]],\n",
    "    }\n",
    ")\n",
    "parameter_plt_frame = forecast_soln_i.loc[:, [c for c in answer_frame.columns]].melt()\n",
    "(\n",
    "    ggplot()\n",
    "    + geom_density(\n",
    "        data=parameter_plt_frame,\n",
    "        mapping=aes(x=\"value\", fill=\"variable\", color=\"variable\"),\n",
    "        linetype=\"\",\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    + geom_vline(\n",
    "        data=answer_frame.melt(),\n",
    "        mapping=aes(xintercept=\"value\", color=\"variable\", fill=\"variable\"),\n",
    "        linetype=\"dashed\",\n",
    "        size=1,\n",
    "    )\n",
    "    + facet_wrap(\"variable\", scales=\"free\")\n",
    "    + scale_color_brewer(type=\"qualitative\", palette=\"Dark2\")\n",
    "    + scale_fill_brewer(type=\"qualitative\", palette=\"Dark2\")\n",
    "    + ggtitle(\"Stan inferred parameter distributions\\n(generating values dashed lines)\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell13",
   "metadata": {},
   "source": [
    "And we can plot both the forecasts, and *estimated* quantile bands around the estimated forecasts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot inference over time\n",
    "plt_i, s_frame_i = plot_forecast(\n",
    "    forecast_soln_i,\n",
    "    d_test,\n",
    "    model_name=\"Stan correct externals model\",\n",
    "    external_regressors=[\"z_0\", \"x_0\"],\n",
    ")\n",
    "plt_i.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7851cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_soln_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c046411",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting_quantiles = [0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95]\n",
    "plotting_colors = {\n",
    "    \"0.05\": \"#66c2a4\",\n",
    "    \"0.1\": \"#2ca25f\",\n",
    "    \"0.25\": \"#006d2c\",\n",
    "    \"0.5\": \"#005824\",\n",
    "    \"0.75\": \"#006d2c\",\n",
    "    \"0.9\": \"#2ca25f\",\n",
    "    \"0.95\": \"#66c2a4\",\n",
    "}\n",
    "ribbon_pairs = [(\"0.05\", \"0.95\"), (\"0.1\", \"0.9\"), (\"0.25\", \"0.75\")]\n",
    "sf_frame = forecast_soln_i.loc[\n",
    "    :, [c.startswith(\"y[\") for c in forecast_soln_i.columns]\n",
    "].reset_index(drop=True, inplace=False)\n",
    "sf_frame[\"trajectory_id\"] = range(sf_frame.shape[0])\n",
    "sf_frame = sf_frame.melt(\n",
    "    id_vars=[\"trajectory_id\"], var_name=\"time_tick\", value_name=\"y\"\n",
    ")\n",
    "sf_frame[\"time_tick\"] = [\n",
    "    int(c.replace(\"y[\", \"\").replace(\"]\", \"\")) for c in sf_frame[\"time_tick\"]\n",
    "]\n",
    "sf_frame = (\n",
    "    sf_frame.loc[:, [\"time_tick\", \"y\"]]\n",
    "    .groupby([\"time_tick\"])\n",
    "    .quantile(plotting_quantiles)\n",
    "    .reset_index(drop=False)\n",
    ")\n",
    "sf_frame.rename(columns={\"level_1\": \"quantile\"}, inplace=True)\n",
    "sf_frame[\"quantile\"] = [str(v) for v in sf_frame[\"quantile\"]]\n",
    "sf_p = sf_frame.pivot(index=\"time_tick\", columns=\"quantile\")\n",
    "sf_p.columns = [c[1] for c in sf_p.columns]\n",
    "sf_p = sf_p.reset_index(drop=False, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f500f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = ggplot()\n",
    "plt = (\n",
    "    plt\n",
    "    + geom_point(\n",
    "        data=d_train,\n",
    "        mapping=aes(x=\"time_tick\", y=\"y\"),\n",
    "        size=2,\n",
    "    )\n",
    "    + geom_step(\n",
    "        data=sf_frame.loc[sf_frame[\"quantile\"] == \"0.5\", :],\n",
    "        mapping=aes(x=\"time_tick\", y=\"y\"),\n",
    "        direction=\"mid\",\n",
    "        color=\"#005824\",\n",
    "    )\n",
    ")\n",
    "for r_min, r_max in ribbon_pairs:\n",
    "    plt = plt + geom_ribbon(\n",
    "        data=sf_p,\n",
    "        mapping=aes(x=\"time_tick\", ymin=r_min, ymax=r_max),\n",
    "        fill=plotting_colors[r_min],\n",
    "        alpha=0.4,\n",
    "        linetype=\"\",\n",
    "    )\n",
    "plt = plt + xlim(900, 1000) + ggtitle(\"data leading to a projection into the future\")\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808ac0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = ggplot()\n",
    "plt = (\n",
    "    plt\n",
    "    + geom_point(\n",
    "        data=d_test,\n",
    "        mapping=aes(x=\"time_tick\", y=\"y\"),\n",
    "        size=2,\n",
    "    )\n",
    "    + geom_point(\n",
    "        data=d_train,\n",
    "        mapping=aes(x=\"time_tick\", y=\"y\"),\n",
    "        size=2,\n",
    "    )\n",
    "    + geom_step(\n",
    "        data=sf_frame.loc[sf_frame[\"quantile\"] == \"0.5\", :],\n",
    "        mapping=aes(x=\"time_tick\", y=\"y\"),\n",
    "        direction=\"mid\",\n",
    "        color=\"#005824\",\n",
    "    )\n",
    ")\n",
    "for r_min, r_max in ribbon_pairs:\n",
    "    plt = plt + geom_ribbon(\n",
    "        data=sf_p,\n",
    "        mapping=aes(x=\"time_tick\", ymin=r_min, ymax=r_max),\n",
    "        fill=plotting_colors[r_min],\n",
    "        alpha=0.4,\n",
    "        linetype=\"\",\n",
    "    )\n",
    "plt = (\n",
    "    plt\n",
    "    + xlim(900, 1000)\n",
    "    + ggtitle(\n",
    "        \"data leading to a projection into the future, matched to held out future\"\n",
    "    )\n",
    ")\n",
    "plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot quality of fit as a scatter plot\n",
    "d_test[\"Stan (correct externals structure) prediction\"] = extract_sframe_result(\n",
    "    s_frame_i\n",
    ")\n",
    "plot_model_quality(\n",
    "    d_test=d_test,\n",
    "    result_name=\"Stan (correct externals structure) prediction\",\n",
    "    external_regressors=[\"z_0\", \"x_0\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot quality as a function of how far out we are predicting\n",
    "plot_model_quality_by_prefix(\n",
    "    s_frame=s_frame_i,\n",
    "    d_test=d_test,\n",
    "    result_name=\"Stan (correct externals structure) prediction\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell17",
   "metadata": {},
   "source": [
    "The model identifies 3 very valuable things:\n",
    "\n",
    "  * Estimates of the model parameters: \n",
    "     * `b_auto_0`\n",
    "     * `b_auto[0]`\n",
    "     * `b_auto[1]`\n",
    "     * `b_x_dur[0]`\n",
    "     * `b_x_imp[0]`\n",
    "  * Projections or applications of the model for future `time_tick`s 950 through 999.\n",
    "  * Good inferences of the most recent unobserved states `y_auto[948]` and `y_auto[949]` in the training period.\n",
    "\n",
    "The third item provides a much more useful estimate of then hidden state (based on evaluation of trajectories through the entire training period) than the simple single point estimate `y_auto[i] ~ y[i] * b_x_impl[0] - x_0[i]`. One can evolve estimates forward from these inferences, and that is not always the case for the simple expected value estimates.\n",
    "\n",
    "The issue with the simple (or naive) estimates being: they are single value point estimates, not necessarily compatible with *any* of the estimate sampling trajectories. Plugging in the naive estimates often does not allow one to evolve the prediction trajectories forward in a sensible manner. The detailed estimates from the Stan sampler do allow such forward evolution of estimates (either inside the Stan sampler as shown, or as a simple external procedure).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67154cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get distribution of breakdown of predictions\n",
    "history_frame = (\n",
    "    forecast_soln_i\n",
    "        .loc[:, [c for c in forecast_soln_i.columns if c.startswith('y[') or c.startswith('y_auto[')]]\n",
    "        .reset_index(drop=True, inplace=False)\n",
    ")\n",
    "idx_max = np.max([int(c.replace('y[', '').replace(']', '')) for c in history_frame.columns if c.startswith('y[')])\n",
    "new_cols = {}\n",
    "for i in range(idx_max + 1):\n",
    "    new_cols[f'y_transient[{i}]'] = history_frame[f'y[{i}]'] - history_frame[f'y_auto[{i}]']\n",
    "history_frame = pd.concat([history_frame, pd.DataFrame(new_cols)], axis=1)\n",
    "history_frame['trajectory_id'] = range(history_frame.shape[0])\n",
    "history_frame = history_frame.melt(id_vars=['trajectory_id'])\n",
    "history_frame['time_tick'] = [int(re.sub(r'^.*\\[', '', v).replace(']', '')) for v in history_frame['variable']]\n",
    "history_frame['variable'] = [re.sub(r'\\[.*\\]', '', v) for v in history_frame['variable']]\n",
    "history_plot = (\n",
    "    history_frame\n",
    "        .loc[:, ['variable', 'value', 'time_tick']]\n",
    "        .groupby(['variable', 'time_tick'])\n",
    "        .median()\n",
    "        .reset_index(drop=False, inplace=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d5b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx0 = d_train.shape[0] - 2 * d_test.shape[0]\n",
    "d_actuals_train = d_train.loc[:, ['time_tick', 'y', 'ext_regressors']].reset_index(drop=True, inplace=False)\n",
    "d_actuals_train['variable'] = 'y'\n",
    "d_actuals_test = d_test.loc[:, ['time_tick', 'y', 'ext_regressors']].reset_index(drop=True, inplace=False)\n",
    "d_actuals_test['variable'] = 'y'\n",
    "(\n",
    "    ggplot(\n",
    "        data=history_plot.loc[history_plot['time_tick'] >= idx0, :],\n",
    "        mapping=aes(x='time_tick', y='value')\n",
    "    )\n",
    "    + annotate(\n",
    "        \"rect\",\n",
    "        xmin=-np.inf, \n",
    "        xmax=d_train.shape[0], \n",
    "        ymin=-np.inf, \n",
    "        ymax=np.inf,\n",
    "        alpha=0.5,\n",
    "        fill='#e0d7c6',\n",
    "    )\n",
    "    + facet_wrap('variable', ncol=1, scales='free_y')\n",
    "    + geom_step(direction=\"mid\", size=1)\n",
    "    + geom_vline(xintercept=d_train.shape[0], alpha=0.5, linetype='dashed')\n",
    "    + geom_point(\n",
    "        data=d_actuals_train.loc[d_actuals_train['time_tick'] >= idx0, :],\n",
    "        mapping=aes(x='time_tick', y='y', color='ext_regressors', shape='ext_regressors'),\n",
    "        size=2,\n",
    "    )\n",
    "    + geom_point(\n",
    "        data=d_actuals_test.loc[d_actuals_test['time_tick'] >= idx0, :],\n",
    "        mapping=aes(x='time_tick', y='y', color='ext_regressors', shape='ext_regressors'),\n",
    "        size=1,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    + ggtitle('past and future visits decomposed into sub-populations\\n(left side training, right side forecast)')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96faa661",
   "metadata": {},
   "source": [
    "The calling sequence to do this in Stan from Python is as follows. One can also call Stan from the command line or from R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26468dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"```python\\n{inspect.getsource(solve_forecast_by_Stan)}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell20",
   "metadata": {},
   "source": [
    "## Bayesian method without external regressors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell21",
   "metadata": {},
   "source": [
    "Let's get back to overall methodology.\n",
    "\n",
    "As a lower-bound on model quality we can try a Bayesian (Stan) model without external regressors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a Stan model without external predictors\n",
    "stan_model_with_forecast_0, stan_model_with_forecast_src_0 = (\n",
    "    define_Stan_model_with_forecast_period(\n",
    "        application_lags=modeling_lags,\n",
    "        n_transient_external_regressors=0,\n",
    "        n_durable_external_regressors=0,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the model specification\n",
    "print(stan_model_with_forecast_src_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cell24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from Stan model solutions\n",
    "forecast_soln_0 = solve_forecast_by_Stan(\n",
    "    model=stan_model_with_forecast_0,\n",
    "    d_train=d_train,\n",
    "    d_apply=d_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize parameter estimates\n",
    "forecast_soln_0.loc[:, [c for c in forecast_soln_0 if c.startswith(\"b_\")]].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show original generative parameters\n",
    "generating_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot fit over time\n",
    "plt_0, s_frame_0 = plot_forecast(\n",
    "    forecast_soln_0,\n",
    "    d_test,\n",
    "    model_name=\"Stan no externals\",\n",
    "    external_regressors=[\"z_0\", \"x_0\"],\n",
    ")\n",
    "plt_0.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell28",
   "metadata": {},
   "source": [
    "Notice both the predictions are \"middle of the road\" estimates again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot quality of fit as a scatter plot\n",
    "d_test[\"Stan (no externals model) prediction\"] = extract_sframe_result(s_frame_0)\n",
    "plot_model_quality(\n",
    "    d_test=d_test,\n",
    "    result_name=\"Stan (no externals model) prediction\",\n",
    "    external_regressors=[\"z_0\", \"x_0\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell31",
   "metadata": {},
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell32",
   "metadata": {},
   "source": [
    "And that concludes our note on modeling in the presence of external regressors. The main point is: one has to specify the structure of the regressors. Do they cause durable effects (such as marketing efforts) or do they cause transient effects (such as one-off sales events)? Also: we would like such specifications to be in terms familiar to domain experts, and not deep in ARMAX or transfer function terminology.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prob_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
