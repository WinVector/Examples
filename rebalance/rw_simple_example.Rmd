---
title: "rw_simple_example"
output: github_document
---

Support code for the article ["Tailored Models are Not The Same as Simple Corrections"](https://win-vector.com/2020/10/11/tailored-models-are-not-the-same-as-simple-corrections/).


```{r}
# attach our packages
library(wrapr)
set.seed(2024)


# build our example data
# modeling y as a function of x1 and x2 (plus intercept)
d <- wrapr::build_frame(
  "x1"  , "x2", "y", "w1", "w2" |
    0   , 0   , 0  , 2   , 4    |
    0   , 1   , 1  , 1   , 5    |
    1   , 0   , 0  , 2   , 4    |
    1   , 0   , 1  , 1   , 5    |
    1   , 1   , 0  , 1   , 2    )

# display table
knitr::kable(d)
```

```{r}
# fit a model at prevalence 0.2857143
m_0.29 <- glm(
  y ~ x1 + x2,
  data = d,
  weights = w1,
  family = binomial())
# add in predictions
d$pred_m_0.29 <- predict(
  m_0.29, newdata = d, type = 'response')

coef(m_0.29)
```

```{r}
# fit a model at prevalence 0.5
m_0.50 <- glm(
  y ~ x1 + x2,
  data = d,
  weights = w2,
  family = binomial())
# add in predictions
d$pred_m_0.50 <- predict(
  m_0.50, newdata = d, type = 'response')

coef(m_0.50)
```

```{r}
# display table
knitr::kable(d)
```

Now notice the relative order of the predictions in rows 1 and 5 are reversed in model `m_0.50` relative to the order given by model `m_0.29`.

```{r}
comps <- d[c(1, 4), qc(pred_m_0.29, pred_m_0.50)]
stopifnot(comps[1, 'pred_m_0.29'] != comps[2, 'pred_m_0.29'])
stopifnot(comps[1, 'pred_m_0.50'] != comps[2, 'pred_m_0.50'])
stopifnot((comps[1, 'pred_m_0.29'] >= comps[2, 'pred_m_0.29']) != (comps[1, 'pred_m_0.50'] >= comps[2, 'pred_m_0.50']))

knitr::kable(comps)
```

This means no monotone correction that looks only at the predictions can make the same adaptations as these two prevalence tailored models. And that is our demonstration. 

As a side note, notice each model is unbiased in the simple sense it matches the expected value of the outcome *with respect to the data weighting it was trained on*. This is part of the advantage of [tailored models](https://win-vector.com/2020/10/10/upcoming-series-probability-model-homotopy/).

```{r}
mean(d$y) - mean(d$pred_m_0.29)

(sum(d$w2 * d$y) / sum(d$w2))  -  (sum(d$w2 * d$pred_m_0.50) / sum(d$w2))
```


A censoring process that doesn't change the prevalence tends not to show the above effect.

```{r}
# replicate data frame by w2 weights
d_expanded <- lapply(
  seq(nrow(d)),
  function(row_i) {
    do.call(rbind, rep(list(d[row_i, c('x1', 'x2', 'y')]), d[row_i, 'w2']))
  })
d_expanded <- do.call(rbind, d_expanded)
rownames(d_expanded) <- NULL
# expand to a large re-sampling
large_size <- 100000
group_size <- 5
d_large <- d_expanded[sample.int(nrow(d_expanded), size=large_size, replace=TRUE) , , drop=FALSE]
d_large$presentation_group <- do.call(
  c, 
  lapply(
    seq(large_size / group_size), 
    function(group_i) {rep(group_i, group_size)}
    ))
d_large$row_id <- seq(large_size)
rownames(d_large) <- NULL
# mark random positive per group
d_sel <- d_large
d_sel$random_order <- runif(n=large_size)
d_sel <- d_sel[d_sel$y==1, , drop=FALSE]
d_sel <- d_sel[order(d_sel$presentation_group, d_sel$random_order), , drop=FALSE]
d_sel$sampled_positive <- c(
  TRUE, 
  d_sel$presentation_group[seq(2, nrow(d_sel))] != d_sel$presentation_group[seq(nrow(d_sel)-1)])
d_large$sampled_positive = FALSE
d_large$sampled_positive[d_sel$row_id[d_sel$sampled_positive]] = TRUE

write.csv(d_large, file='d_large.csv', row.names = FALSE)
```


```{r}
knitr::kable(d_large[seq(10), , drop=FALSE])
```


Effect if we supress some positives by changing them to negatives (independently).

```{r}
# limit down to at most one positive per group by changing outcomes (indpendently)
d_large_censored_changed <- d_large
d_large_censored_changed$y = d_large_censored_changed$y * d_large_censored_changed$sampled_positive
```



```{r}
knitr::kable(d_large_censored_changed[seq(10), , drop=FALSE])
```


```{r}
# fit on large sample
m_large <- glm(
  y ~ x1 + x2,
  data = d_large,
  family = binomial())

summary(m_large)
```

```{r}
p_large <- predict(m_large, newdata=d, type='response')

```



```{r}
# fit on large censored sample
m_large_censored_changed <- glm(
  y ~ x1 + x2,
  data = d_large_censored_changed,
  family = binomial())

summary(m_large_censored_changed)
```

```{r}
p_large_censored_changed <- predict(m_large_censored_changed, newdata=d, type='response')

```

```{r}
c_large_censored_changed <- data.frame(
  x1=d$x1,
  x2=d$x2,
  y=d$y,
  p_large=p_large, 
  p_large_censored_changed=p_large_censored_changed)

knitr::kable(c_large_censored_changed)
```


```{r}
comps_censored_changed <- c_large_censored_changed[c(1, 2), , drop=FALSE]
stopifnot(comps_censored_changed[1, 'p_large'] != comps_censored_changed[2, 'p_large'])
stopifnot(comps_censored_changed[1, 'p_large_censored_changed'] != comps_censored_changed[2, 'p_large_censored_changed'])
stopifnot((comps_censored_changed[1, 'p_large'] >= comps_censored_changed[2, 'p_large_censored_changed']) != (comps_censored_changed[1, 'pred_m_0.50'] >= comps_censored_changed[2, 'p_large_censored_changed']))

knitr::kable(comps_censored_changed)
```


Effect if we suppress some positives by deletign rows (independently).

```{r}
# limit down to at most one positive per group by censoring out some positive rows
d_large_censored_deleted <- d_large[d_large$sampled_positive | (d_large$y == 0), , drop=FALSE]
```


```{r}
knitr::kable(d_large_censored_deleted[seq(10), , drop=FALSE])
```


```{r}
# fit on large sample
m_large <- glm(
  y ~ x1 + x2,
  data = d_large,
  family = binomial())

summary(m_large)
```

```{r}
p_large <- predict(m_large, newdata=d, type='response')

```



```{r}
# fit on large censored sample
m_large_censored_deleted <- glm(
  y ~ x1 + x2,
  data = d_large_censored_deleted,
  family = binomial())

summary(m_large_censored_deleted)
```

```{r}
p_large_censored_deleted <- predict(m_large_censored_deleted, newdata=d, type='response')

```

```{r}
c_large_censored_deleted <- data.frame(
  x1=d$x1,
  x2=d$x2,
  y=d$y,
  p_large=p_large, 
  p_large_censored_deleted=p_large_censored_deleted)

knitr::kable(c_large_censored_deleted)
```


```{r}
comps_censored_deleted <- c_large_censored_deleted[c(1, 2), , drop=FALSE]
stopifnot(comps_censored_deleted[1, 'p_large'] != comps_censored_deleted[2, 'p_large'])
stopifnot(comps_censored_deleted[1, 'p_large_censored_deleted'] != comps_censored_deleted[2, 'p_large_censored_deleted'])
stopifnot((comps_censored_deleted[1, 'p_large'] >= comps_censored_deleted[2, 'p_large_censored_deleted']) != (comps_censored_deleted[1, 'pred_m_0.50'] >= comps_censored_deleted[2, 'p_large_censored_deleted']))

knitr::kable(comps_censored_deleted)
```


