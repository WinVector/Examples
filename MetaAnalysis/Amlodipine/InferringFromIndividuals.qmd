---
title: "Infering From Individuals"
author: John Mount
date: "2024-11-29"
format: markdown_github
code-fold: true
code-summary: "Show the code"
bibliography: references.bib
---

Joseph Rickert and I put together an experiment trying to both run a standard meta-analysis and then reproduce similar results directly using Bayesian methods. I think it came out really interesting and we share it here at [R Works](https://rworks.dev/posts/meta-analysis/) and also [here on Github](https://github.com/WinVector/Examples/blob/main/MetaAnalysis/Amlodipine/ExaminingMetaAnalysis.md).

In this note we examine how inference would work *if studies shared the data* instead of sharing summary statistics.

## Example

Let's begin: load the required required packages and read in the data.

```{r}
#| warning: false
#| message: false
#| code-fold: true
#| code-summary: "Show the code"

library(wrapr)

angina <- read.csv(
  file = "AmlodipineData.csv", 
  strip.white = TRUE, 
  stringsAsFactors = FALSE)

angina |>
  knitr::kable()
```

The data set contains eight rows each representing the measured effects of treatment and control on different groups. The column definitions are:

  * `Protocol` id number of the study the row is summarizing.
  * `nE` number of patients in the treatment group.
  * `meanE` mean treatment effect observed.
  * `varE` variance of treatment effect observed.
  * `nC` number of patients in the control group.
  * `meanC` mean control effect observed.
  * `varC` variance of control effect observed.

### Bayesian analysis

Let's re-run the Bayesian analysis, this time capturing plausible example data.

```{r, warning=FALSE, error=FALSE, results=FALSE}
#| message: false
#| code-fold: true
#| code-summary: "Show the code"


# attach packages
library(ggplot2)
library(rstan)
library(digest)
source("define_Stan_model.R")

n_studies = nrow(angina)
# make strings for later use
descriptions = vapply(
  seq(n_studies),
  function(i) { paste0(
    'Protocol ', angina[i, 'Protocol'], ' (',
    'nE=', angina[i, 'nE'], ', meanE=', angina[i, 'meanE'],
    ', nC=', angina[i, 'nC'], ', meanC=', angina[i, 'meanC'],
    ')') },
  character(1))

unpack[
  analysis_src_joint_Stan = src_Stan, 
  analysis_src_joint_Latex = src_Latex
  ] := define_Stan_model(n_studies = n_studies, model_style = "per group means")

stan_data = list(
  n_studies = n_studies,
  nE = array(angina$nE, dim = n_studies),  # deal with length 1 arrays confused with scalars in JSON path
  meanE = array(angina$meanE, dim = n_studies),
  varE = array(angina$varE, dim = n_studies), 
  nC = array(angina$nC, dim = n_studies), 
  meanC = array(angina$meanC, dim = n_studies), 
  varC = array(angina$varC, dim = n_studies))
```

```{r, warning=FALSE, error=FALSE, results=FALSE}
#| message: false
#| code-fold: true
#| code-summary: "Show the code"

whole_job_fn <- function() {
  # run the sampling procedure
  fit_joint <- stan(
    model_code = analysis_src_joint_Stan,  # Stan program
    data = stan_data,           # named list of data
    chains = 4,                 # number of Markov chains
    warmup = 2000,              # number of warmup iterations per chain
    iter = 4000,                # total number of iterations per chain
    cores = 4,                  # number of cores (could use one per chain)
    refresh = 0,                # no progress shown
    pars = c("lp__",  # parameters to bring back
           "inferred_grand_treatment_mean", "inferred_grand_control_mean", 
           "inferred_between_group_stddev",
           "inferred_group_treatment_mean", "inferred_group_control_mean",
           "inferred_in_group_stddev", 
           "sampled_meanE", "sampled_varE",
           "sampled_meanC", "sampled_varC",
           paste0('treatment_subject_', seq(n_studies)),
           paste0('control_subject_', seq(n_studies)))
    )
  # extract the results.
  # primary inference
  fit_joint <- fit_joint |>
    as.data.frame() 
  fit_joint['delta'] <- (
    fit_joint['inferred_grand_treatment_mean'] 
    - fit_joint['inferred_grand_control_mean'])
  inference <- fit_joint |>
    (`[`)(c(
      "inferred_grand_treatment_mean", 
      "inferred_grand_control_mean", 
      "inferred_between_group_stddev",
      "delta")) |>
    colMeans() |>
    as.list() |>
    data.frame()
  # extract enough to plot
  plt_frame <- fit_joint[ 
    , 
    c('inferred_grand_treatment_mean', 
      'inferred_grand_control_mean',
      'delta')]
  # extract a sample of individual subject data
  subject_column_names <- colnames(fit_joint)[
    grep('_subject_', colnames(fit_joint))]
  individual_sample <- fit_joint[1, subject_column_names]
  vector_names <- sort(unique(gsub('\\[.+\\]', '', subject_column_names)))
  vectors <- lapply(
    vector_names,
    function(nm) as.numeric(individual_sample[
      1,
      colnames(individual_sample)[grep(nm, colnames(individual_sample))]
    ]))
  names(vectors) <- vector_names
  return(list(
    inference = inference,
    plt_frame = plt_frame,
    vectors = vectors
  ))
}


unpack[    
  inference = inference,
  plt_frame = plt_frame,
  vectors = vectors] := run_cached(
  whole_job_fn,
  list(),
  prefix="Amlodipine_joint_individuals"
)
```


```{r}
#| code-fold: true
#| code-summary: "Show the code"

# show primary inference
inference |>
  knitr::kable()
```

We can plot the estimated distribution effects in the treatment and control groups.

```{r}
#| code-fold: true
#| code-summary: "Show the code"

# plot the grand group inferences 
dual_density_plot(
  plt_frame, 
  c1 = 'inferred_grand_treatment_mean', 
  c2 = 'inferred_grand_control_mean',
  title = 'effect estimates, hierarchical model dependent means and independent variances')
```

We also plot the estimated net difference in treatment and control effects.


```{r}
#| code-fold: true
#| code-summary: "Show the code"
# plot the grand group inferences 
ggplot(
  data = plt_frame,
  mapping = aes(x=delta),
  ) +
  geom_density(fill='green', alpha=0.5) +
  geom_vline(
    xintercept = inference['delta'][[1]], 
    linetype=2,
    alpha=0.8) +
  ggtitle("estimated distribution of treatment minus control effect")
```

Let's extract some sampled individuals to simulate how the analysis would work if the individual outcomes had been shared. We don't expect we have de-censored or guessed the actual individual data. However we know by our sampling specification these example are considired similar to the actual data conditioned on the shared summary statistics. So if we *pretend* these were the data we can estimate uncertainty that would have been present when estimated parameters from this data and then compare that to the uncertainty we just plotted when trying to estimate parameters from statistical summaries.


```{r}
#| code-fold: true
#| code-summary: "Show the code"

vectors
```



